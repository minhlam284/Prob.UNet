import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from dataset.transform import TransformDataset
import random

def get_mmis_dataset(args, mode: str = ""):
    train_dataset, val_dataset = None, None

    if mode in ["train", "both"]:
        train_dataset = MMISDataset(data_dir=args.data_dir, mode="train", mask_type=args.mask_type)
        train_dataset = TransformDataset(train_dataset, image_size=args.image_size)

    if mode in ["val", "both"]:
        val_dataset = MMISDataset(data_dir=args.data_dir, mode="val", mask_type=args.mask_type)
        val_dataset = TransformDataset(val_dataset, image_size=args.image_size)

    return train_dataset, val_dataset


import os
import numpy as np
import torch
from torch.utils.data import Dataset

class MMISDataset(Dataset):
    def __init__(self, data_dir, mode="train", mask_type=""):
        self.data_dir = data_dir
        self.mode = mode
        self.mask_type = mask_type
        self.data = {"images": [], "masks": []}
        self.masks_per_image = 4  # Sá»‘ lÆ°á»£ng mask cho má»—i áº£nh (a1, a2, a3, a4)
        
        print("ğŸ”¥ MMISDataset loaded from:", __file__)
        # Duyá»‡t qua cÃ¡c file trong thÆ° má»¥c con (train hoáº·c val)
        images_folder = os.path.join(data_dir, mode)
        self.load_data(images_folder)

    def load_data(self, images_folder):
        print(f"Loading data from {images_folder}")

        # Duyá»‡t qua táº¥t cáº£ cÃ¡c file áº£nh trong thÆ° má»¥c con (train/val)
        for filename in os.listdir(images_folder):
            if filename.endswith('_image.npy'):
                base_name = filename.replace('_image.npy', '')
                image_path = os.path.join(images_folder, filename)
                
                # Táº£i áº£nh
                image = np.load(image_path)

                # Táº£i cÃ¡c mask tÆ°Æ¡ng á»©ng (label_a1, label_a2, label_a3, label_a4)
                masks = []
                for i in range(1, 5):
                    mask_path = os.path.join(images_folder, f"{base_name}_label_a{i}.npy")
                    if os.path.exists(mask_path):
                        mask = np.load(mask_path)
                        masks.append(mask)
                    else:
                        # Náº¿u mask khÃ´ng tá»“n táº¡i, cÃ³ thá»ƒ bá» qua hoáº·c táº¡o mask máº·c Ä‘á»‹nh
                        masks.append(np.zeros_like(image))  # Táº¡o mask trá»‘ng (tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i mask cÃ³ giÃ¡ trá»‹ 0)

                # ThÃªm áº£nh vÃ  mask vÃ o danh sÃ¡ch
                self.data["images"].append(image)
                self.data["masks"].append(masks)

        print(f"Loaded {len(self.data['images'])} images and masks")

    def __len__(self):
        return len(self.data["images"])

    def __getitem__(self, index):
        image = self.data["images"][index]
        # Chuáº©n hÃ³a áº£nh
        if image.max() > image.min():
            image = (image - image.min()) / (image.max() - image.min())

        if image.ndim == 3 and image.shape[2] == 3:
            image = np.mean(image, axis=2)
        # image = image[np.newaxis, ...]

        if self.mask_type == "random":
            mask_id = random.randint(0, self.masks_per_image - 1)
            mask = self.data["masks"][index][mask_id]
        else:
            mask = self.data["masks"][index]
            if self.mask_type == "ensemble":
                mask = np.stack(mask, axis=-1).mean(axis=-1)
                mask = (mask > 0.5).astype(np.uint8)
            elif self.mask_type == "multi":
                pass
        print(f"Image shape: {image.shape}, Mask shape: {mask.shape}")
        return mask, image

if __name__ == "__main__":
    class Args:
        data_dir = '/Users/kaiser_1/Documents/Data/mmis'  # ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c dá»¯ liá»‡u
        mask_type = "random"  # Loáº¡i mask cáº§n sá»­ dá»¥ng (vÃ­ dá»¥: "multi")
        image_size = 128  # KÃ­ch thÆ°á»›c áº£nh sau khi biáº¿n Ä‘á»•i
    
    args = Args()
    train_dataset, val_dataset = get_mmis_dataset_np(args, mode="both")

    print(f"Train dataset size: {len(train_dataset)}")
    print(f"Validation dataset size: {len(val_dataset)}")

    # Kiá»ƒm tra má»™t vÃ­ dá»¥
    image, mask = train_dataset[0]
    print(f"Image shape: {image.shape}")
    print(f"Mask shape: {mask.shape}")
    
    # Táº¡o DataLoader
    dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)

    # Kiá»ƒm tra batch Ä‘áº§u tiÃªn
    for batch_images, batch_masks in dataloader:
        print(f"Batch images shape: {batch_images.shape}")
        print(f"Batch masks shape: {batch_masks.shape}")
        break
